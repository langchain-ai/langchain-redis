{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Redis Kitchen Sink Example\n",
    "\n",
    "This notebook demonstrates a comprehensive example that combines RedisVectorStore, RedisCache, and RedisChatMessageHistory to create a powerful, efficient, and context-aware chatbot system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-redis in /home/jupyter/venv/lib/python3.11/site-packages (0.0.1)\n",
      "Requirement already satisfied: langchain-openai in /home/jupyter/venv/lib/python3.11/site-packages (0.1.14)\n",
      "Requirement already satisfied: wikipedia in /home/jupyter/venv/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-redis) (0.2.11)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-redis) (1.26.4)\n",
      "Requirement already satisfied: python-ulid<3.0.0,>=2.7.0 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-redis) (2.7.0)\n",
      "Requirement already satisfied: redisvl<0.3.0,>=0.2.3 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-redis) (0.2.3)\n",
      "Requirement already satisfied: sentence-transformers<4.0.0,>=3.0.1 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-redis) (3.0.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-openai) (1.35.9)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jupyter/venv/lib/python3.11/site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /home/jupyter/venv/lib/python3.11/site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain-redis) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain-redis) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain-redis) (0.1.83)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain-redis) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain-redis) (2.8.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain-redis) (8.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/jupyter/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jupyter/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jupyter/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /home/jupyter/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/jupyter/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/jupyter/venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: coloredlogs in /home/jupyter/venv/lib/python3.11/site-packages (from redisvl<0.3.0,>=0.2.3->langchain-redis) (15.0.1)\n",
      "Requirement already satisfied: redis>=5.0.0 in /home/jupyter/venv/lib/python3.11/site-packages (from redisvl<0.3.0,>=0.2.3->langchain-redis) (5.0.7)\n",
      "Requirement already satisfied: tabulate<1,>=0.9.0 in /home/jupyter/venv/lib/python3.11/site-packages (from redisvl<0.3.0,>=0.2.3->langchain-redis) (0.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyter/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyter/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jupyter/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyter/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.6.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /home/jupyter/venv/lib/python3.11/site-packages (from sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (4.42.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/jupyter/venv/lib/python3.11/site-packages (from sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /home/jupyter/venv/lib/python3.11/site-packages (from sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (1.5.1)\n",
      "Requirement already satisfied: scipy in /home/jupyter/venv/lib/python3.11/site-packages (from sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (1.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /home/jupyter/venv/lib/python3.11/site-packages (from sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (0.23.4)\n",
      "Requirement already satisfied: Pillow in /home/jupyter/venv/lib/python3.11/site-packages (from sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (10.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/jupyter/venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyter/venv/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jupyter/venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/jupyter/venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: filelock in /home/jupyter/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jupyter/venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (2024.6.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jupyter/venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-redis) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jupyter/venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-redis) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jupyter/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-redis) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in /home/jupyter/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-redis) (2.20.0)\n",
      "Requirement already satisfied: sympy in /home/jupyter/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/jupyter/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/jupyter/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (3.1.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyter/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/jupyter/venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (0.19.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/jupyter/venv/lib/python3.11/site-packages (from coloredlogs->redisvl<0.3.0,>=0.2.3->langchain-redis) (10.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/jupyter/venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/jupyter/venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jupyter/venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/jupyter/venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers<4.0.0,>=3.0.1->langchain-redis) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-redis langchain-openai wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure you have a Redis server running. You can start one using Docker with:\n",
    "\n",
    "```\n",
    "docker run -d -p 6379:6379 redis:latest\n",
    "```\n",
    "\n",
    "Or install and run Redis locally according to your operating system's instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Redis at: redis://redis:6379\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the environment variable if set, otherwise default to localhost\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "print(f\"Connecting to Redis at: {REDIS_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_redis import RedisVectorStore, RedisCache, RedisChatMessageHistory\n",
    "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key not found in environment variables.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your OpenAI API key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key has been set for this session.\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "# Check if OPENAI_API_KEY is already set in the environment\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    print(\"OpenAI API key not found in environment variables.\")\n",
    "    openai_api_key = getpass(\"Please enter your OpenAI API key: \")\n",
    "\n",
    "    # Set the API key for the current session\n",
    "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "    print(\"OpenAI API key has been set for this session.\")\n",
    "else:\n",
    "    print(\"OpenAI API key found in environment variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Index with RedisVL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll set up our vector store using RedisVL, which provides a powerful interface for creating and managing vector indexes in Redis. We'll define a schema for our Wikipedia data, create an index using RedisVL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redis import Redis\n",
    "from redisvl.index import SearchIndex\n",
    "from redisvl.schema import IndexSchema\n",
    "from langchain_redis import RedisConfig, RedisVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RedisVL Index Schema\n",
    "\n",
    "We start by defining a schema for our index. This schema includes:\n",
    "- A text field for the document content\n",
    "- A text field for metadata\n",
    "- A vector field for the document embeddings\n",
    "\n",
    "The vector field is configured with 1536 dimensions (suitable for OpenAI embeddings), using cosine distance and a FLAT index algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = IndexSchema.from_dict(\n",
    "    {\n",
    "        \"index\": {\n",
    "            \"name\": \"kitchensink_docs\",\n",
    "            \"storage_type\": \"hash\",\n",
    "            \"prefix\": \"wiki:\",\n",
    "        },\n",
    "        \"fields\": [\n",
    "            {\"name\": \"text\", \"type\": \"text\"},\n",
    "            {\"name\": \"url\", \"type\": \"tag\"},\n",
    "            {\"name\": \"title\", \"type\": \"text\"},\n",
    "            {\n",
    "                \"name\": \"embedding\",\n",
    "                \"type\": \"vector\",\n",
    "                \"attrs\": {\n",
    "                    \"dims\": 1536,\n",
    "                    \"distance_metric\": \"cosine\",\n",
    "                    \"algorithm\": \"FLAT\",\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the RedisVL Index\n",
    "\n",
    "Using the defined schema, we create a SearchIndex object and use it to create the actual index in Redis. This step sets up the structure that our vector store will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish Redis connection and define index\n",
    "redis_client = Redis.from_url(REDIS_URL)\n",
    "\n",
    "# Create the index using RedisVL\n",
    "redisvl_index = SearchIndex(schema, redis_client)\n",
    "redisvl_index.create(overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing RedisVectorStore\n",
    "\n",
    "With the RedisVL index in place, we can now initialize our RedisVectorStore. We use a RedisConfig object to specify the index name and Redis URL, ensuring that our vector store connects to the correct index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:12:08 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    }
   ],
   "source": [
    "# Initialize RedisVectorStore using the pre-constructed index\n",
    "config = RedisConfig(\n",
    "    index_name=\"kitchensink_docs\", redis_url=REDIS_URL, from_existing=True\n",
    ")\n",
    "vector_store = RedisVectorStore(OpenAIEmbeddings(), config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Components\n",
    "\n",
    "We also initialize other components like RedisCache for LLM caching, ChatOpenAI for our language model, and RedisChatMessageHistory for maintaining conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RedisCache\n",
    "redis_cache = RedisCache(redis_url=REDIS_URL)\n",
    "set_llm_cache(redis_cache)\n",
    "\n",
    "# Initialize ChatOpenAI with caching\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "# Initialize RedisChatMessageHistory\n",
    "message_history = RedisChatMessageHistory(\"kitchensink_chat\", redis_url=REDIS_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate Vector Store with Wikipedia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 439 document chunks to the vector store.\n"
     ]
    }
   ],
   "source": [
    "## Populate Vector Store with Wikipedia Data\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "def fetch_wikipedia_content(titles):\n",
    "    documents = []\n",
    "    for title in titles:\n",
    "        try:\n",
    "            page = wikipedia.page(title)\n",
    "            doc = Document(\n",
    "                page_content=page.content, metadata={\"title\": title, \"url\": page.url}\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        except wikipedia.exceptions.DisambiguationError as e:\n",
    "            # Choose the first option from the disambiguation list\n",
    "            page = wikipedia.page(e.options[0])\n",
    "            doc = Document(\n",
    "                page_content=page.content,\n",
    "                metadata={\"title\": e.options[0], \"url\": page.url},\n",
    "            )\n",
    "            documents.append(doc)\n",
    "        except wikipedia.exceptions.PageError:\n",
    "            print(f\"Page not found for {title}\")\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Fetch some Wikipedia articles\n",
    "titles = [\n",
    "    \"Artificial Intelligence\",\n",
    "    \"Deep Learning\",\n",
    "    \"Natural Language Processing\",\n",
    "    \"Large Language Models\",\n",
    "    \"Robotics\",\n",
    "]\n",
    "documents = fetch_wikipedia_content(titles)\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Add to vector store\n",
    "vector_store.add_documents(splits)\n",
    "\n",
    "print(f\"Added {len(splits)} document chunks to the vector store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the retriever\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "def combine_chat_history_and_question(inputs):\n",
    "    return f\"Chat History: {inputs['chat_history']}\\nHuman: {inputs['question']}\"\n",
    "\n",
    "\n",
    "# Update the prompt template to include chat history\n",
    "prompt_template = \"\"\"\n",
    "    You are an AI assistant answering questions based on the provided context and chat history. Be concise and accurate.\n",
    "\n",
    "    Context: {context}\n",
    "    {question}\n",
    "    AI Assistant:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Create the RAG chain\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: format_docs(retriever.invoke(x[\"question\"])),\n",
    "        \"question\": combine_chat_history_and_question,\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the AI Assistant! Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  What are the core tenets of AI?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "The core tenets of AI include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. These are the traditional goals of AI research and are essential for creating intelligent machines that can perform tasks on par with humans. Additionally, AI also draws upon various fields such as psychology, linguistics, philosophy, neuroscience, and others to further advance its capabilities.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  How does AI influence robotics, and viceversa?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "AI and robotics have a symbiotic relationship, as advancements in one field often lead to advancements in the other. AI influences robotics by providing the software and algorithms that enable robots to make decisions and learn from their environment. On the other hand, robotics influences AI by providing real-world data and challenges for AI systems to learn from and improve upon. Together, they are driving the development of advanced technologies that have the potential to greatly impact various industries and aspects of our daily lives.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Human:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for using the AI Assistant!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "def get_chat_history(history):\n",
    "    return \"\\n\".join(\n",
    "        [f\"{msg.type.capitalize()}: {msg.content}\" for msg in history.messages[-5:]]\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Welcome to the AI Assistant! Type 'exit' to end the conversation.\")\n",
    "\n",
    "chat_history = []\n",
    "while True:\n",
    "    user_input = input(\"Human: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Add user message to history\n",
    "    message_history.add_user_message(user_input)\n",
    "\n",
    "    # Get response from RAG chain\n",
    "    result = rag_chain.invoke(\n",
    "        {\"question\": user_input, \"chat_history\": get_chat_history(message_history)}\n",
    "    )\n",
    "\n",
    "    # Add AI message to history\n",
    "    message_history.add_ai_message(result)\n",
    "\n",
    "    print(f\"AI: {result}\")\n",
    "\n",
    "print(\"Thank you for using the AI Assistant!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the Kitchen Sink Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates the integration of multiple Redis-based components in LangChain:\n",
    "\n",
    "1. **RedisVectorStore**: Used to store and retrieve document chunks from Wikipedia articles. It enables efficient similarity search for relevant context.\n",
    "\n",
    "2. **RedisCache**: Implemented to cache LLM responses, potentially speeding up repeated or similar queries.\n",
    "\n",
    "3. **RedisChatMessageHistory**: Stores the conversation history, allowing the AI to maintain context across multiple interactions.\n",
    "\n",
    "The combination of these components creates a powerful, context-aware chatbot system with the following features:\n",
    "\n",
    "- **Efficient Information Retrieval**: The vector store allows quick access to relevant information from a large dataset.\n",
    "- **Improved Response Time**: Caching helps in reducing API calls for similar or repeated queries.\n",
    "- **Contextual Understanding**: The chat history enables the AI to reference previous parts of the conversation.\n",
    "- **Scalability**: Redis as a backend allows this system to handle large amounts of data and high traffic efficiently.\n",
    "\n",
    "This kitchen sink example showcases how these Redis-based components can work together seamlessly in a real-world application, demonstrating the power and flexibility of the langchain-redis package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanup completed.\n"
     ]
    }
   ],
   "source": [
    "# Clear vector store\n",
    "vector_store.index.delete(drop=True)\n",
    "\n",
    "# Clear cache\n",
    "redis_cache.clear()\n",
    "\n",
    "# Clear chat history\n",
    "message_history.clear()\n",
    "\n",
    "print(\"Cleanup completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
