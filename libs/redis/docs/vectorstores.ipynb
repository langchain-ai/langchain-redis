{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RedisVectorStore\n",
    "\n",
    "This notebook demonstrates the usage of RedisVectorStore from the langchain-redis package. RedisVectorStore leverages Redis as a vector database, enabling efficient storage, retrieval, and similarity search of vector embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, we need to install the necessary packages. Run the following command to install langchain-redis, sentence-transformers, and scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-redis in /home/jupyter/venv/lib/python3.11/site-packages (0.0.1)\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: sentence-transformers in /home/jupyter/venv/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: scikit-learn in /home/jupyter/venv/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-redis) (0.2.11)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-redis) (1.26.4)\n",
      "Requirement already satisfied: python-ulid<3.0.0,>=2.7.0 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-redis) (2.7.0)\n",
      "Requirement already satisfied: redisvl<0.3.0,>=0.2.3 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-redis) (0.2.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-huggingface) (0.23.4)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-huggingface) (0.19.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-huggingface) (4.42.3)\n",
      "Requirement already satisfied: tqdm in /home/jupyter/venv/lib/python3.11/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/jupyter/venv/lib/python3.11/site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: scipy in /home/jupyter/venv/lib/python3.11/site-packages (from sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: Pillow in /home/jupyter/venv/lib/python3.11/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/jupyter/venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/jupyter/venv/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /home/jupyter/venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jupyter/venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jupyter/venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jupyter/venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/jupyter/venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyter/venv/lib/python3.11/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain-redis) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain-redis) (0.1.83)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain-redis) (2.8.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/jupyter/venv/lib/python3.11/site-packages (from langchain-core<0.3,>=0.1.52->langchain-redis) (8.4.2)\n",
      "Requirement already satisfied: coloredlogs in /home/jupyter/venv/lib/python3.11/site-packages (from redisvl<0.3.0,>=0.2.3->langchain-redis) (15.0.1)\n",
      "Requirement already satisfied: redis>=5.0.0 in /home/jupyter/venv/lib/python3.11/site-packages (from redisvl<0.3.0,>=0.2.3->langchain-redis) (5.0.7)\n",
      "Requirement already satisfied: tabulate<1,>=0.9.0 in /home/jupyter/venv/lib/python3.11/site-packages (from redisvl<0.3.0,>=0.2.3->langchain-redis) (0.9.0)\n",
      "Requirement already satisfied: sympy in /home/jupyter/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: networkx in /home/jupyter/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/jupyter/venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyter/venv/lib/python3.11/site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyter/venv/lib/python3.11/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/jupyter/venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-redis) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/jupyter/venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-redis) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jupyter/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-redis) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.0 in /home/jupyter/venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-redis) (2.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyter/venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyter/venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jupyter/venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyter/venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/jupyter/venv/lib/python3.11/site-packages (from coloredlogs->redisvl<0.3.0,>=0.2.3->langchain-redis) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jupyter/venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /home/jupyter/venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: langchain-huggingface\n",
      "Successfully installed langchain-huggingface-0.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-redis langchain-huggingface sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "We'll import the necessary libraries for our tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_redis import RedisVectorStore\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Redis Connection\n",
    "To use RedisVectorStore, you need a running Redis instance. For this example, we assume a local Redis instance running on the default port. Modify the URL if your setup differs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Redis at: redis://redis:6379\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the environment variable if set, otherwise default to localhost\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "print(f\"Connecting to Redis at: {REDIS_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that Redis is up an running by pinging it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "redis_client = redis.from_url(REDIS_URL)\n",
    "redis_client.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Sample Data\n",
    "We'll use a subset of the 20 Newsgroups dataset for this demonstration. This dataset contains newsgroup posts on various topics. We'll focus on two categories: 'alt.atheism' and 'sci.space':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [\"alt.atheism\", \"sci.space\"]\n",
    "newsgroups = fetch_20newsgroups(\n",
    "    subset=\"train\", categories=categories, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "# Use only the first 250 documents\n",
    "texts = newsgroups.data[:250]\n",
    "metadata = [\n",
    "    {\"category\": newsgroups.target_names[target]} for target in newsgroups.target[:250]\n",
    "]\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadata)\n",
    "]\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the first document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'category': 'alt.atheism'}, page_content='From: bil@okcforum.osrhe.edu (Bill Conner)\\nSubject: Re: Not the Omni!\\nNntp-Posting-Host: okcforum.osrhe.edu\\nOrganization: Okcforum Unix Users Group\\nX-Newsreader: TIN [version 1.1 PL6]\\nLines: 18\\n\\nCharley Wingate (mangoe@cs.umd.edu) wrote:\\n: \\n: >> Please enlighten me.  How is omnipotence contradictory?\\n: \\n: >By definition, all that can occur in the universe is governed by the rules\\n: >of nature. Thus god cannot break them. Anything that god does must be allowed\\n: >in the rules somewhere. Therefore, omnipotence CANNOT exist! It contradicts\\n: >the rules of nature.\\n: \\n: Obviously, an omnipotent god can change the rules.\\n\\nWhen you say, \"By definition\", what exactly is being defined;\\ncertainly not omnipotence. You seem to be saying that the \"rules of\\nnature\" are pre-existant somehow, that they not only define nature but\\nactually cause it. If that\\'s what you mean I\\'d like to hear your\\nfurther thoughts on the question.\\n\\nBill\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Embeddings\n",
    "We'll use the SentenceTransformer model to create embeddings. This model runs locally and doesn't require an API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f05e1d9ee24be0a3314b21516fd0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a579747a73ec4ea7b6ef404af2855f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e921782f9e924c8f821cb04260ab80b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88df7211ebff425aaea406be0404f03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d25e33415df4601945264eb230d05a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84a93395d714a45b4140bbed3d972c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2f2b8514f54c13867a9df43f7d1895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550a363df9c14c7f8fc99696ae70879b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2311124f92eb4c4181fc9804eeb34228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d445534f58ef4b6fbec2328b683c9ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74b00ee78364c2a9175e559bd26aaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"msmarco-distilbert-base-v4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage with LangChain's RedisVectorStore\n",
    "Now we'll demonstrate basic usage of RedisVectorStore, including creating an instance, inserting data, and performing a simple similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a RedisVectorStore instance and inserting data\n",
    "We'll create a RedisVectorStore instance and populate it with our sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = RedisVectorStore.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    redis_url=REDIS_URL,\n",
    "    index_name=\"newsgroups\",\n",
    "    metadata_schema=[\n",
    "        {\"name\": \"category\", \"type\": \"tag\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a simple similarity search\n",
    "Let's perform a basic similarity search using a query about space exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Similarity Search Results:\n",
      "Content: From: aa429@freenet.carleton.ca (Terry Ford)\n",
      "Subject: A flawed propulsion system: Space Shuttle\n",
      "X-Ad...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n",
      "Content: From: nsmca@aurora.alaska.edu\n",
      "Subject: Space Design Movies?\n",
      "Article-I.D.: aurora.1993Apr23.124722.1\n",
      "...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about space exploration\"\n",
    "results = vector_store.similarity_search(query, k=2)\n",
    "\n",
    "print(\"Simple Similarity Search Results:\")\n",
    "for doc in results:\n",
    "    print(f\"Content: {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Queries with RedisVectorStore\n",
    "RedisVectorStore supports more advanced query types. We'll demonstrate similarity search with metadata filtering, maximum marginal relevance search, and similarity search with score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity search with metadata filtering\n",
    "We can filter our search results based on metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Similarity Search Results:\n",
      "Content: From: aa429@freenet.carleton.ca (Terry Ford)\n",
      "Subject: A flawed propulsion system: Space Shuttle\n",
      "X-Ad...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n",
      "Content: From: nsmca@aurora.alaska.edu\n",
      "Subject: Space Design Movies?\n",
      "Article-I.D.: aurora.1993Apr23.124722.1\n",
      "...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from redisvl.query.filter import Tag\n",
    "\n",
    "query = \"Tell me about space exploration\"\n",
    "\n",
    "# Create a filter expression\n",
    "filter_condition = Tag(\"category\") == \"sci.space\"\n",
    "\n",
    "filtered_results = vector_store.similarity_search(query, k=2, filter=filter_condition)\n",
    "\n",
    "print(\"Filtered Similarity Search Results:\")\n",
    "for doc in filtered_results:\n",
    "    print(f\"Content: {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum marginal relevance search\n",
    "Maximum marginal relevance search helps in getting diverse results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Marginal Relevance Search Results:\n",
      "Content: From: aa429@freenet.carleton.ca (Terry Ford)\n",
      "Subject: A flawed propulsion system: Space Shuttle\n",
      "X-Ad...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n",
      "Content: From: moroney@world.std.com (Michael Moroney)\n",
      "Subject: Re: Vulcan? (No, not the guy with the ears!)\n",
      "...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Maximum marginal relevance search with filter\n",
    "mmr_results = vector_store.max_marginal_relevance_search(\n",
    "    query, k=2, fetch_k=10, filter=filter_condition\n",
    ")\n",
    "\n",
    "print(\"Maximum Marginal Relevance Search Results:\")\n",
    "for doc in mmr_results:\n",
    "    print(f\"Content: {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity search with score\n",
    "We can also get similarity scores along with our search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Search with Score Results:\n",
      "Content: From: aa429@freenet.carleton.ca (Terry Ford)\n",
      "Subject: A flawed propulsion system: Space Shuttle\n",
      "X-Ad...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "Score: 0.569670796394\n",
      "\n",
      "Content: From: nsmca@aurora.alaska.edu\n",
      "Subject: Space Design Movies?\n",
      "Article-I.D.: aurora.1993Apr23.124722.1\n",
      "...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "Score: 0.590400338173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Similarity search with score and filter\n",
    "scored_results = vector_store.similarity_search_with_score(\n",
    "    query, k=2, filter=filter_condition\n",
    ")\n",
    "\n",
    "print(\"Similarity Search with Score Results:\")\n",
    "for doc, score in scored_results:\n",
    "    print(f\"Content: {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(f\"Score: {score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "After we're done, it's important to clean up our Redis indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the underlying index and it's data\n",
    "vector_store.index.delete(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
