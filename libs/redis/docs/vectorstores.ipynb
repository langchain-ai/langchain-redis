{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RedisVectorStore\n",
    "\n",
    "This notebook demonstrates the usage of RedisVectorStore from the langchain-redis package. RedisVectorStore leverages Redis as a vector database, enabling efficient storage, retrieval, and similarity search of vector embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, we need to install the necessary packages. Run the following command to install langchain-redis, sentence-transformers, and scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-redis langchain-huggingface sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "We'll import the necessary libraries for our tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_redis import RedisVectorStore\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Redis Connection\n",
    "To use RedisVectorStore, you need a running Redis instance. For this example, we assume a local Redis instance running on the default port. Modify the URL if your setup differs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Redis at: redis://redis:6379\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Use the environment variable if set, otherwise default to localhost\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "print(f\"Connecting to Redis at: {REDIS_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that Redis is up an running by pinging it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "redis_client = redis.from_url(REDIS_URL)\n",
    "redis_client.ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Sample Data\n",
    "We'll use a subset of the 20 Newsgroups dataset for this demonstration. This dataset contains newsgroup posts on various topics. We'll focus on two categories: 'alt.atheism' and 'sci.space':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [\"alt.atheism\", \"sci.space\"]\n",
    "newsgroups = fetch_20newsgroups(\n",
    "    subset=\"train\", categories=categories, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "# Use only the first 250 documents\n",
    "texts = newsgroups.data[:250]\n",
    "metadata = [\n",
    "    {\"category\": newsgroups.target_names[target]} for target in newsgroups.target[:250]\n",
    "]\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadata)\n",
    "]\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the first document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'category': 'alt.atheism'}, page_content='From: bil@okcforum.osrhe.edu (Bill Conner)\\nSubject: Re: Not the Omni!\\nNntp-Posting-Host: okcforum.osrhe.edu\\nOrganization: Okcforum Unix Users Group\\nX-Newsreader: TIN [version 1.1 PL6]\\nLines: 18\\n\\nCharley Wingate (mangoe@cs.umd.edu) wrote:\\n: \\n: >> Please enlighten me.  How is omnipotence contradictory?\\n: \\n: >By definition, all that can occur in the universe is governed by the rules\\n: >of nature. Thus god cannot break them. Anything that god does must be allowed\\n: >in the rules somewhere. Therefore, omnipotence CANNOT exist! It contradicts\\n: >the rules of nature.\\n: \\n: Obviously, an omnipotent god can change the rules.\\n\\nWhen you say, \"By definition\", what exactly is being defined;\\ncertainly not omnipotence. You seem to be saying that the \"rules of\\nnature\" are pre-existant somehow, that they not only define nature but\\nactually cause it. If that\\'s what you mean I\\'d like to hear your\\nfurther thoughts on the question.\\n\\nBill\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Embeddings\n",
    "We'll use the SentenceTransformer model to create embeddings. This model runs locally and doesn't require an API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9808d9a483435db845c0c344dd397e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a304d22c044bc9a3d435d03cce0517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda6d78c2e614d3a9577f5d0a85781c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce77d1ed6ca948abac49117c4faee84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "679c66002046426494eb72dd53a26ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae3fbe3a2204432b4cc839df8fac550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67aa7349a7546d396c235d0e40b9a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/319 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af86c3b9a4b94be8b1f746dc55e462a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3228def50c92404abea598d7df475d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc71682b68d4db8b17c1fca31b33309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1e77fc9c0e4180a1aaf0612978a7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"msmarco-distilbert-base-v4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage with LangChain's RedisVectorStore\n",
    "Now we'll demonstrate basic usage of RedisVectorStore, including creating an instance, inserting data, and performing a simple similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a RedisVectorStore instance and inserting data\n",
    "We'll create a RedisVectorStore instance and populate it with our sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = RedisVectorStore.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    redis_url=REDIS_URL,\n",
    "    index_name=\"newsgroups\",\n",
    "    metadata_schema=[\n",
    "        {\"name\": \"category\", \"type\": \"tag\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a simple similarity search\n",
    "Let's perform a basic similarity search using a query about space exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Similarity Search Results:\n",
      "Content: From: aa429@freenet.carleton.ca (Terry Ford)\n",
      "Subject: A flawed propulsion system: Space Shuttle\n",
      "X-Ad...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n",
      "Content: From: nsmca@aurora.alaska.edu\n",
      "Subject: Space Design Movies?\n",
      "Article-I.D.: aurora.1993Apr23.124722.1\n",
      "...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me about space exploration\"\n",
    "results = vector_store.similarity_search(query, k=2)\n",
    "\n",
    "print(\"Simple Similarity Search Results:\")\n",
    "for doc in results:\n",
    "    print(f\"Content: {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Queries with RedisVectorStore\n",
    "RedisVectorStore supports more advanced query types. We'll demonstrate similarity search with metadata filtering, maximum marginal relevance search, and similarity search with score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity search with metadata filtering\n",
    "We can filter our search results based on metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Similarity Search Results:\n",
      "Content: From: aa429@freenet.carleton.ca (Terry Ford)\n",
      "Subject: A flawed propulsion system: Space Shuttle\n",
      "X-Ad...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n",
      "Content: From: nsmca@aurora.alaska.edu\n",
      "Subject: Space Design Movies?\n",
      "Article-I.D.: aurora.1993Apr23.124722.1\n",
      "...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from redisvl.query.filter import Tag\n",
    "\n",
    "query = \"Tell me about space exploration\"\n",
    "\n",
    "# Create a filter expression\n",
    "filter_condition = Tag(\"category\") == \"sci.space\"\n",
    "\n",
    "filtered_results = vector_store.similarity_search(query, k=2, filter=filter_condition)\n",
    "\n",
    "print(\"Filtered Similarity Search Results:\")\n",
    "for doc in filtered_results:\n",
    "    print(f\"Content: {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum marginal relevance search\n",
    "Maximum marginal relevance search helps in getting diverse results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Marginal Relevance Search Results:\n",
      "Content: From: aa429@freenet.carleton.ca (Terry Ford)\n",
      "Subject: A flawed propulsion system: Space Shuttle\n",
      "X-Ad...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n",
      "Content: From: moroney@world.std.com (Michael Moroney)\n",
      "Subject: Re: Vulcan? (No, not the guy with the ears!)\n",
      "...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Maximum marginal relevance search with filter\n",
    "mmr_results = vector_store.max_marginal_relevance_search(\n",
    "    query, k=2, fetch_k=10, filter=filter_condition\n",
    ")\n",
    "\n",
    "print(\"Maximum Marginal Relevance Search Results:\")\n",
    "for doc in mmr_results:\n",
    "    print(f\"Content: {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity search with score\n",
    "We can also get similarity scores along with our search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Search with Score Results:\n",
      "Content: From: aa429@freenet.carleton.ca (Terry Ford)\n",
      "Subject: A flawed propulsion system: Space Shuttle\n",
      "X-Ad...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "Score: 0.569670975208\n",
      "\n",
      "Content: From: nsmca@aurora.alaska.edu\n",
      "Subject: Space Design Movies?\n",
      "Article-I.D.: aurora.1993Apr23.124722.1\n",
      "...\n",
      "Metadata: {'category': 'sci.space'}\n",
      "Score: 0.590400338173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Similarity search with score and filter\n",
    "scored_results = vector_store.similarity_search_with_score(\n",
    "    query, k=2, filter=filter_condition\n",
    ")\n",
    "\n",
    "print(\"Similarity Search with Score Results:\")\n",
    "for doc, score in scored_results:\n",
    "    print(f\"Content: {doc.page_content[:100]}...\")\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(f\"Score: {score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "After we're done, it's important to clean up our Redis indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the underlying index and it's data\n",
    "vector_store.index.delete(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
